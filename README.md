# ![Lucky Llama-x Logo](assets/TinyLlama-x_logo.png)
# ğŸ±â€ğŸ’» TinyLlama-X

**TinyLlama-X** is an all-in-one terminal AI companion for Linux, designed to assist users from **Linux newcomers to advanced users**. It leverages TinyLlama models to provide interactive AI functionality directly in your terminal, without the need for web browsers or cloud services.

---

## ğŸš€ Features

- **Text Generation** â€“ Ask questions or generate text using TinyLlama models.  
- **Interactive Terminal AI** â€“ Engage in a chat-like interface directly in your Linux terminal.  
- **Lightweight and Local** â€“ Runs fully locally, using minimal resources.  
- **Flexible Scripts** â€“ Multiple entry scripts for auto-start, advanced usage, and testing.  
- **Model Management** â€“ Easily switch between TinyLlama models.  
- **ASCII Logo & Branding** â€“ Fun terminal banner when starting the app.

---

## ğŸ›  Installation

1. Clone the repository:

```bash
git clone https://github.com/120git/tinyllama-x.git
cd tinyllama-x

2. Create a Python virtual environment:

python3 -m venv ai-env
source ai-env/bin/activate


3. Install dependencies:

pip install --upgrade pip
pip install -r requirements.txt


4. Download or place your TinyLlama model in the models/ folder:

models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf

ğŸ’» Usage

Start the TinyLlama-X terminal app:

./ai_terminal_llama.sh

r for auto-start with your preferred model:

./ai_terminal_llama_auto.sh


Exit anytime by typing:

exit


ğŸ“‚ File Structure

tinyllama-x/
â”œâ”€ ai_terminal.sh                  # Main AI terminal script
â”œâ”€ ai_terminal_llama.sh            # Llama chat script
â”œâ”€ ai_terminal_llama_auto.sh       # Auto-start Llama script
â”œâ”€ run-llama.py                    # TinyLlama launcher
â”œâ”€ run-tinyllama.py                # TinyLlama launcher
â”œâ”€ models/                         # Folder for Llama models
â”‚  â””â”€ tinyllama-1.1b-chat.v1.Q4_K_M.gguf
â”œâ”€ output/                         # Generated outputs/logs
â”œâ”€ README.md                        # This file
â””â”€ LICENSE                         # MIT License


âš¡ Recommended Workflow

1. Activate the environment:

source ai-env/bin/activate

2. Launch your preferred script:

./ai_terminal_llama.sh


3. Chat, explore AI capabilities, or test text generation.

ğŸ“ Notes

Keep large model files out of Git repository; include them in .gitignore.

Ensure pip and Python are updated for best performance.

Terminal is optimized for Linux but should work on macOS with minor adjustments.

ğŸ“œ License

This project is licensed under the MIT License. See LICENSE
 for details.

ğŸ‘¾ ASCII Logo

  TL  <-X->

Termininja Engaged


